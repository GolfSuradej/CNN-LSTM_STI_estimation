{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Libaries\n",
    "import os\n",
    "import time\n",
    "import numpy as np \n",
    "from random import shuffle\n",
    "# --- Signal Processing Libary\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter, freqz, hilbert, filtfilt\n",
    "import librosa\n",
    "# --- Machine Learining\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset \n",
    "dataset_path = \"datasetSTI/\"\n",
    "files = os.listdir(dataset_path)\n",
    "OVdim = 700000 #Sample length (44.1kHz)\n",
    "reDim = 253969 #Dimension after down sampling(16kHz)\n",
    "X_data = np.zeros((len(files),OVdim))\n",
    "Y_data = np.zeros((len(files),1))\n",
    "X_data = X_data.astype('float32')\n",
    "Y_data = Y_data.astype('float32') \n",
    "#smaller new dimension dataset\n",
    "x_data = np.zeros((len(files),reDim))\n",
    "x_data = X_data.astype('float32')\n",
    "i=0\n",
    "for wav in files:  \n",
    "    #Read wav data\n",
    "    if not wav.endswith(\".wav\"): continue\n",
    "    Fs,signal = wavfile.read(dataset_path+wav)\n",
    "    X = np.array(signal)\n",
    "    if(OVdim-len(X)>0):\n",
    "        Xpad = np.pad(X, (0, OVdim-len(X)), mode='constant')\n",
    "        X_data[i]=np.array(Xpad)\n",
    "        #Read label (Speech Transmission Idex) from file name\n",
    "        rt = int(wav[0:4])\n",
    "        rt /=10000\n",
    "        Y_data[i] = rt\n",
    "        i += 1\n",
    "    else:\n",
    "        print(\"dimension is not enought for some records!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down sampling to 16kS/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = librosa.resample(X_data, Fs, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension at 44.1 kS/s : 700000\n",
      "Dimension at 16.0 kS/s : 253969\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating dataset to Tune, Train and test Set\n",
    "index = np.linspace(0,len(files)-1,len(files))\n",
    "shuffle(index) #Shuffle Data\n",
    "\n",
    "tuningSet = 20\n",
    "trainingSet = 70\n",
    "testSet = len(files)- noTune - noTrain\n",
    "\n",
    "x_tune = np.zeros([tuningSet,reDim])#5000\n",
    "y_tune = np.zeros([tuningSet,1])\n",
    "x_train = np.zeros([trainingSet,reDim])#30000\n",
    "y_train = np.zeros([trainingSet,1])\n",
    "x_test = np.zeros([testSet,reDim])#the least\n",
    "y_test = np.zeros([testSet,1])\n",
    "x_train = x_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "x_tune = x_tune.astype('float32')\n",
    "y_tune = y_tune.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "for i in range(20):\n",
    "    x_tune[i]= x_data[int(index[i])]\n",
    "    y_tune[i]= Y_data[int(index[i])]\n",
    "j=0\n",
    "for i in range(20,90):\n",
    "    x_train[j]= x_data[int(index[i])]\n",
    "    y_train[j]= Y_data[int(index[i])] \n",
    "    j +=1\n",
    "j=0    \n",
    "for i in range(90,len(files)):\n",
    "    x_test[j]= x_data[int(index[i])]\n",
    "    y_test[j]= Y_data[int(index[i])]\n",
    "    j +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-band Envelope Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=3):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=3):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "fcentre = [125,250,500,1000,2000,4000,8000] # Center freq.-Octave band \n",
    "fc = 30 # cutoff frequency of the speech envelope  at 30 Hz\n",
    "w_L = 2*fc/Fs\n",
    "\n",
    "bz, az = butter(6,w_L, 'low')#lowpas filter order '6'\n",
    "fd = np.power(2,1/2)\n",
    "\n",
    "Fs = 16000 #441000 #new Sampling rate\n",
    "\n",
    "y_subband = np.zeros([7,reDim])\n",
    "y_env = np.zeros([7,reDim])\n",
    "y_env_rs = np.zeros([7,2000])\n",
    "y_env_ds = np.zeros([7,1588])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tune_fea= np.zeros([len(x_tune),6352])\n",
    "x_tune_fea = x_tune_fea.astype('float32')\n",
    "\n",
    "for k in range(1):#(len(x_tune)):\n",
    "    for i in range(3,7):\n",
    "        highcut = fcentre[i] *fd\n",
    "        lowcut = fcentre[i]/fd\n",
    "        b, a = butter_bandpass(lowcut, highcut, Fs, order=6)      \n",
    "        \n",
    "        y_subband[i] = filtfilt(b,a,x_tune[k])     #Octave filter\n",
    "        y_env[i] = filtfilt(bz,az,np.abs(hilbert(y_subband[i])))  #Envelope extraction\n",
    "        #y_env_ds[i] = librosa.resample(y_env[i], Fs, 100)\n",
    "    \n",
    "    Env_concat = np.hstack((y_env_ds[3],y_env_ds[4],y_env_ds[5],y_env_ds[6]))     \n",
    "    #x_tune_fea[k] =  librosa.util.normalize(Env_concat, fill=True) #Normalized   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_fea= np.zeros([len(x_tune),6352])\n",
    "x_train_fea = x_train_fea.astype('float32')\n",
    "\n",
    "for k in range(len(x_train)):\n",
    "    for i in range(3,7):\n",
    "        highcut = fcentre[i] *fd\n",
    "        lowcut = fcentre[i]/fd\n",
    "        b, a = butter_bandpass(lowcut, highcut, Fs, order=6)      \n",
    "        \n",
    "        y_subband[i] = filtfilt(b,a,x_rain[k])     #Octave filter\n",
    "        y_env[i] = filtfilt(bz,az,np.abs(hilbert(y_subband[i])))  #Envelope extraction\n",
    "        y_env_ds[i] = librosa.resample(y_env[i], Fs, 100)\n",
    "    \n",
    "    Env_concat = np.hstack((y_env_ds[3],y_env_ds[4],y_env_ds[5],y_env_ds[6]))     \n",
    "    x_train_fea[k] =  librosa.util.normalize(Env_concat, fill=True) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_fea= np.zeros([len(x_tune),6352])\n",
    "x_test_fea = x_test_fea.astype('float32')\n",
    "\n",
    "for k in range(1):#(len(x_tune)):\n",
    "    for i in range(3,7):\n",
    "        highcut = fcentre[i] *fd\n",
    "        lowcut = fcentre[i]/fd\n",
    "        b, a = butter_bandpass(lowcut, highcut, Fs, order=6)      \n",
    "        \n",
    "        y_subband[i] = filtfilt(b,a,x_test[k])     #Octave filter\n",
    "        y_env[i] = filtfilt(bz,az,np.abs(hilbert(y_subband[i])))  #Envelope extraction\n",
    "        y_env_ds[i] = librosa.resample(y_env[i], Fs, 100)\n",
    "    \n",
    "    Env_concat = np.hstack((y_env_ds[3],y_env_ds[4],y_env_ds[5],y_env_ds[6]))     \n",
    "    x_tune_fea[k] =  librosa.util.normalize(Env_concat, fill=True) #Normalized   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(y_env[3])\n",
    "plt.subplot(213)\n",
    "plt.plot(y_env[4])\n",
    "plt.subplot(221)\n",
    "plt.plot(y_env[5])\n",
    "plt.subplot(222)\n",
    "plt.plot(y_env[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save features array to file (.npy)\n",
    "np.save('x_tune_fea', x_tune_fea)\n",
    "np.save('x_train_fea', x_train_fea)\n",
    "np.save('x_test_fea', x_test_fea)\n",
    "np.save('y_tune', y_tune)\n",
    "np.save('y_train', y_train)\n",
    "np.save('y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 2000\n",
    "embedding_vecor_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=2724))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy','mse'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length,\n",
    "                    input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128, drop_out = 0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#optimizer='adam'\n",
    "model.compile(loss='mse', \n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_tune, y_tune, epochs=3, batch_size=5,shuffle=True, verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=64,shuffle=True  verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------- Evaluation ---------------\n",
    "scores = model.evaluate(x_test_fea,y_test, verbose=0)\n",
    "y_estimation = model.predict(x_test_fea)\n",
    "\n",
    "accuracy = metrics.r2_score(y_test, y_estimation)\n",
    "print (\"Cross-Predicted Accuracy:\", accuracy)\n",
    "print(\"%s:%.3f%%\"%(model.metrics_names[0],score[1]*100))\n",
    "print(\"RMSE:%.3f\",np.sqrt(metrics.mean_squared_error(y_test,y_estimation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-------------- End of Code --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *-------------- debug session ---------------------*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "print(\"Input\",X_data.shape)\n",
    "print(\"Target\",Y_data.shape)\n",
    "print(\"Sampling Rate :\",Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27515717128>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN1GrgJMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x275157092b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_tune[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension at 44.1 kS/s : 700000\n",
      "Dimension at 16.0 kS/s : 253969\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension at 44.1 kS/s : %d\" %len(X_data[3]))\n",
    "print(\"Dimension at 16.0 kS/s : %d\" %len(x_test[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "ITS489_lecture2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
